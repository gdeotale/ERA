{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
      "\u001b[K     |████████████████████████████████| 486 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[K     |████████████████████████████████| 194 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from datasets) (6.7.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-12.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 39.1 MB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.1)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.15-py37-none-any.whl (116 kB)\n",
      "\u001b[K     |████████████████████████████████| 116 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[K     |████████████████████████████████| 110 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.22.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (4.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (2.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: asynctest==0.13.0; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (19.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2019.11.28)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->datasets) (1.14.0)\n",
      "\u001b[31mERROR: multiprocess 0.70.15 has requirement dill>=0.3.7, but you'll have dill 0.3.6 which is incompatible.\u001b[0m\n",
      "Installing collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
      "Successfully installed datasets-2.13.1 dill-0.3.6 multiprocess-0.70.15 pyarrow-12.0.1 xxhash-3.3.0\n",
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting torchtext==0.12.0\n",
      "  Downloading torchtext-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4 MB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchtext==0.12.0) (2.22.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext==0.12.0) (4.66.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtext==0.12.0) (1.21.6)\n",
      "Requirement already satisfied: torch==1.11.0 in /opt/conda/lib/python3.7/site-packages (from torchtext==0.12.0) (1.11.0+cu113)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.12.0) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.12.0) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.12.0) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.12.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.11.0->torchtext==0.12.0) (4.7.1)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.12.0\n",
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting rich\n",
      "  Downloading rich-13.5.2-py3-none-any.whl (239 kB)\n",
      "\u001b[K     |████████████████████████████████| 239 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading Pygments-2.16.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5.0,>=4.0.0; python_version < \"3.9\" in /opt/conda/lib/python3.7/site-packages (from rich) (4.7.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "\u001b[31mERROR: spyder 4.0.1 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: spyder 4.0.1 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "Installing collected packages: mdurl, markdown-it-py, pygments, rich\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.5.2\n",
      "    Uninstalling Pygments-2.5.2:\n",
      "      Successfully uninstalled Pygments-2.5.2\n",
      "Successfully installed markdown-it-py-2.2.0 mdurl-0.1.2 pygments-2.16.1 rich-13.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install torchtext==0.12.0\n",
    "!pip install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py:119: PkgResourcesDeprecationWarning: 4.0.0-unsupported is an invalid version and will not be supported in a future release\n",
      "  PkgResourcesDeprecationWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py:119: PkgResourcesDeprecationWarning: 4.0.0-unsupported is an invalid version and will not be supported in a future release\n",
      "  PkgResourcesDeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "from lit_module import lit_module\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import RichProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:479: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab756feb3b243babac3eee98f9193f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b14c05b64541318c458aced7e6dd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/161k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bacf79df4e3405991c9da6b7db09d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/20.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset opus_books/en-it to /root/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29065ed935b244379c6cf13391495d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.30M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/32332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset opus_books downloaded and prepared to /root/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf. Subsequent calls will reuse this data.\n",
      "Max length of source sentence: 309\n",
      "Max length of target sentence: 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ loss_fn │ CrossEntropyLoss │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ model   │ Transformer      │ 75.1 M │\n",
       "└───┴─────────┴──────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ loss_fn │ CrossEntropyLoss │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ model   │ Transformer      │ 75.1 M │\n",
       "└───┴─────────┴──────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 75.1 M                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 75.1 M                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 300                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 75.1 M                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 75.1 M                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 300                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656654b508e7467a9820cb962e3469b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:491: \n",
       "PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you \n",
       "turn shuffling off for val/test/predict dataloaders.\n",
       "  category=PossibleUserWarning,\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:491: \n",
       "PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you \n",
       "turn shuffling off for val/test/predict dataloaders.\n",
       "  category=PossibleUserWarning,\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the \n",
       "`batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use \n",
       "`self.log(..., batch_size=batch_size)`.\n",
       "  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the \n",
       "`batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use \n",
       "`self.log(..., batch_size=batch_size)`.\n",
       "  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Source:We sat and mused on the prospect.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Source:We sat and mused on the prospect.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TARGET:Ci sedemmo a meditar sulla prospettiva.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TARGET:Ci sedemmo a meditar sulla prospettiva.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">PREDICTED:veruno veruno veruno elevata elevata elevata Lasciammo Lasciammo Lasciammo Lasciammo veruno veruno veruno\n",
       "arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar elevata arrivar elevata oriente inevitabili\n",
       "inevitabili inevitabili legò elevata arrivar elevata arrivar arrivar elevata elevata elevata elevata elevata \n",
       "elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata \n",
       "arrivar elevata elevata elevata elevata elevata arrivar elevata arrivar elevata arrivar elevata elevata elevata \n",
       "elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata \n",
       "arrivar elevata arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar elevata arrivar elevata \n",
       "arrivar elevata sorgere sorgere sorgere legò elevata elevata arrivar elevata arrivar elevata elevata elevata \n",
       "elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata \n",
       "elevata elevata elevata elevata arrivar elevata arrivar elevata arrivar arrivar arrivar arrivar elevata elevata \n",
       "elevata elevata elevata elevata arrivar sorgere sorgere sorgere arrivar elevata arrivar arrivar arrivar arrivar \n",
       "arrivar arrivar arrivar arrivar arrivar arrivar arrivar sorgere sorgere sorgere arrivar arrivar arrivar arrivar \n",
       "arrivar arrivar arrivar inevitabili inevitabili arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar \n",
       "arrivar arrivar arrivar elevata arrivar elevata arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar \n",
       "arrivar arrivar arrivar arrivar arrivar calamaio arrivar calamaio arrivar calamaio sorgere sorgere sorgere sorgere \n",
       "sorgere sorgere sorgere sorgere sorgere arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar \n",
       "arrivar arrivar arrivar arrivar arrivar arrivar legò legò sorgere sorgere sorgere legò arrivar arrivar arrivar \n",
       "sorgere sorgere sorgere arrivar arrivar arrivar arrivar arrivar arrivar sorgere sorgere sorgere sorgere sorgere \n",
       "sorgere sorgere sorgere spaventoso arrivar arrivar sorgere sorgere sorgere sorgere sorgere sorgere sorgere arrivar \n",
       "arrivar arrivar arrivar arrivar sorgere sorgere sorgere sorgere sorgere sorgere sorgere sorgere sorgere arrivar \n",
       "arrivar arrivar sorgere sorgere sorgere sorgere sorgere sorgere sorgere sorgere sorgere sorgere arrivar arrivar \n",
       "arrivar arrivar arrivar legò mali legò mali legò mali sorgere sorgere sorgere sorgere mali spaventoso legò mali \n",
       "spaventoso spaventoso mali mali mali mali sorgere sorgere sorgere legò mali legò legò legò legò legò legò legò legò\n",
       "mali legò legò legò legò mali spaventoso spaventoso spaventoso mali mali mali mali mali spaventoso spaventoso \n",
       "spaventoso sorgere sorgere sorgere spaventoso\n",
       "</pre>\n"
      ],
      "text/plain": [
       "PREDICTED:veruno veruno veruno elevata elevata elevata Lasciammo Lasciammo Lasciammo Lasciammo veruno veruno veruno\n",
       "arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar elevata arrivar elevata oriente inevitabili\n",
       "inevitabili inevitabili legò elevata arrivar elevata arrivar arrivar elevata elevata elevata elevata elevata \n",
       "elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata \n",
       "arrivar elevata elevata elevata elevata elevata arrivar elevata arrivar elevata arrivar elevata elevata elevata \n",
       "elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata \n",
       "arrivar elevata arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar elevata arrivar elevata \n",
       "arrivar elevata sorgere sorgere sorgere legò elevata elevata arrivar elevata arrivar elevata elevata elevata \n",
       "elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata elevata \n",
       "elevata elevata elevata elevata arrivar elevata arrivar elevata arrivar arrivar arrivar arrivar elevata elevata \n",
       "elevata elevata elevata elevata arrivar sorgere sorgere sorgere arrivar elevata arrivar arrivar arrivar arrivar \n",
       "arrivar arrivar arrivar arrivar arrivar arrivar arrivar sorgere sorgere sorgere arrivar arrivar arrivar arrivar \n",
       "arrivar arrivar arrivar inevitabili inevitabili arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar \n",
       "arrivar arrivar arrivar elevata arrivar elevata arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar \n",
       "arrivar arrivar arrivar arrivar arrivar calamaio arrivar calamaio arrivar calamaio sorgere sorgere sorgere sorgere \n",
       "sorgere sorgere sorgere sorgere sorgere arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar arrivar \n",
       "arrivar arrivar arrivar arrivar arrivar arrivar legò legò sorgere sorgere sorgere legò arrivar arrivar arrivar \n",
       "sorgere sorgere sorgere arrivar arrivar arrivar arrivar arrivar arrivar sorgere sorgere sorgere sorgere sorgere \n",
       "sorgere sorgere sorgere spaventoso arrivar arrivar sorgere sorgere sorgere sorgere sorgere sorgere sorgere arrivar \n",
       "arrivar arrivar arrivar arrivar sorgere sorgere sorgere sorgere sorgere sorgere sorgere sorgere sorgere arrivar \n",
       "arrivar arrivar sorgere sorgere sorgere sorgere sorgere sorgere sorgere sorgere sorgere sorgere arrivar arrivar \n",
       "arrivar arrivar arrivar legò mali legò mali legò mali sorgere sorgere sorgere sorgere mali spaventoso legò mali \n",
       "spaventoso spaventoso mali mali mali mali sorgere sorgere sorgere legò mali legò legò legò legò legò legò legò legò\n",
       "mali legò legò legò legò mali spaventoso spaventoso spaventoso mali mali mali mali mali spaventoso spaventoso \n",
       "spaventoso sorgere sorgere sorgere spaventoso\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs = 10,\n",
    "    callbacks = RichProgressBar(leave=True),\n",
    ")\n",
    "model = lit_module()\n",
    "# Train the PyTorch Lightning model\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
