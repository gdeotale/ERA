{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
      "\u001b[K     |████████████████████████████████| 486 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[K     |████████████████████████████████| 194 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from datasets) (6.7.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-12.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 39.1 MB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.1)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.15-py37-none-any.whl (116 kB)\n",
      "\u001b[K     |████████████████████████████████| 116 kB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[K     |████████████████████████████████| 110 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.22.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (4.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (2.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: asynctest==0.13.0; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (19.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2019.11.28)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->datasets) (1.14.0)\n",
      "\u001b[31mERROR: multiprocess 0.70.15 has requirement dill>=0.3.7, but you'll have dill 0.3.6 which is incompatible.\u001b[0m\n",
      "Installing collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
      "Successfully installed datasets-2.13.1 dill-0.3.6 multiprocess-0.70.15 pyarrow-12.0.1 xxhash-3.3.0\n",
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting torchtext==0.12.0\n",
      "  Downloading torchtext-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4 MB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchtext==0.12.0) (2.22.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext==0.12.0) (4.66.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtext==0.12.0) (1.21.6)\n",
      "Requirement already satisfied: torch==1.11.0 in /opt/conda/lib/python3.7/site-packages (from torchtext==0.12.0) (1.11.0+cu113)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.12.0) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.12.0) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.12.0) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.12.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.11.0->torchtext==0.12.0) (4.7.1)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.12.0\n",
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting rich\n",
      "  Downloading rich-13.5.2-py3-none-any.whl (239 kB)\n",
      "\u001b[K     |████████████████████████████████| 239 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading Pygments-2.16.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5.0,>=4.0.0; python_version < \"3.9\" in /opt/conda/lib/python3.7/site-packages (from rich) (4.7.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "\u001b[31mERROR: spyder 4.0.1 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: spyder 4.0.1 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\u001b[0m\n",
      "Installing collected packages: mdurl, markdown-it-py, pygments, rich\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.5.2\n",
      "    Uninstalling Pygments-2.5.2:\n",
      "      Successfully uninstalled Pygments-2.5.2\n",
      "Successfully installed markdown-it-py-2.2.0 mdurl-0.1.2 pygments-2.16.1 rich-13.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install torchtext==0.12.0\n",
    "!pip install rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py:119: PkgResourcesDeprecationWarning: 4.0.0-unsupported is an invalid version and will not be supported in a future release\n",
      "  PkgResourcesDeprecationWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py:119: PkgResourcesDeprecationWarning: 4.0.0-unsupported is an invalid version and will not be supported in a future release\n",
      "  PkgResourcesDeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "from lit_module import lit_module\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import RichProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:479: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Found cached dataset opus_books (/root/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentence: 309\n",
      "Max length of target sentence: 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | loss_fn | CrossEntropyLoss | 0     \n",
      "1 | model   | Transformer      | 75.1 M\n",
      "---------------------------------------------\n",
      "75.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "75.1 M    Total params\n",
      "300.532   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:491: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  category=PossibleUserWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:Levin, having regretfully taken leave of them, mounted and rode home. He looked back from the top of the hill.\n",
      "TARGET:Levin montò a cavallo e, congedatosi con rammarico dai contadini, prese la via del ritorno.\n",
      "PREDICTED:desiderando desiderando desiderando desiderando desiderando desiderando desiderando desiderando desiderando desiderando maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare riceveva riceveva riceveva maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare riceveva riceveva riceveva riceveva riceveva maritare maritare maritare riceveva riceveva riceveva maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare maritare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare torbidi accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare riceveva riceveva riceveva riceveva maritare maritare riceveva riceveva riceveva riceveva riceveva accompagnare accompagnare accompagnare riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva riceveva turbini turbini turbini torbidi maritare maritare maritare maritare maritare maritare maritare riceveva riceveva turbini riceveva turbini turbini turbini turbini turbini turbini turbini turbini turbini turbini turbini turbini turbini turbini turbini turbini turbini turbini turbini accompagnare turbini turbini turbini turbini turbini accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare accompagnare turbini turbini farò farò accompagnare accompagnare accompagnare accompagnare accompagnare farò farò riceveva riceveva riceveva farò accompagnare accompagnare accompagnare farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò riceveva farò riceveva farò riceveva farò riceveva farò riceveva farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò farò\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9873b4d4cffc45e298b44c7a5106a41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:There were the means of washing in the room, and a comb and brush to smooth my hair.\n",
      "TARGET:C'era nella stanza l'occorrente per lavarsi e un pettine e una spazzola.\n",
      "PREDICTED:, e , e , e , e .\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:An extinguished candle stood on the table; she was bending over the fire, and seemed reading in a little black book, like a prayer-book, by the light of the blaze: she muttered the words to herself, as most old women do, while she read; she did not desist immediately on my entrance: it appeared she wished to finish a paragraph.\n",
      "TARGET:La zingara era chinata verso il fuoco e alla luce della fiamma leggeva un libriccino, che aveva l'apparenza di un libro di preghiere, e nel leggere borbottava a voce alta, come fanno talvolta le vecchie. Non interruppe la lettura quando entrai; pareva che dovesse terminare un paragrafo.\n",
      "PREDICTED:Il signor Rochester era un tratto , e la mano , e la mano , e la mano , e la mano , la mano , la mano , la mano , la mano , la mano , non era un tratto la sua mano , ma il signor Rochester era un tratto la sua moglie .\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:Levin's conviction that it was impossible rested on the idea that from her relatives' point of view he was not a good or suitable match for the delightful Kitty, and that Kitty herself could not love him.\n",
      "TARGET:La convinzione di Levin che la cosa non andasse si basava sull’idea che agli occhi dei familiari egli dovesse sembrare un partito poco convincente, non degno della deliziosa Kitty, e che la stessa Kitty non potesse amarlo.\n",
      "PREDICTED:Levin non era più più più che non aveva detto che il suo amore , non aveva mai detto che non aveva detto nulla di un ’ amore , e che non aveva detto , e che non poteva dire .\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:Our disagreement lies in the fact that you consider personal interests the motive power, while I think every man with a certain degree of education ought to be interested in the general welfare.\n",
      "TARGET:Il nostro disaccordo consiste in questo: che tu poni come movente l’interesse personale, e io suppongo che ogni uomo che abbia un certo grado di cultura debba interessarsi del bene comune.\n",
      "PREDICTED:Il nostro lavoro è che tu non vi la sua situazione , e , dopo aver avuto un ’ altra parte , per , per la .\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:He feels in his own sphere.\n",
      "TARGET:Qua egli si sente nel suo ambiente.\n",
      "PREDICTED:E per lui , per lui , si .\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:CHAPTER II The Pool of Tears\n",
      "TARGET:II LO STAGNO DI LAGRIME\n",
      "PREDICTED:II\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:Vasenka greatly admired the Don Steppe horse attached on the left.\n",
      "TARGET:A Vasen’ka piaceva straordinariamente il cavallo di steppa del Don che era al bilancino sinistro.\n",
      "PREDICTED:Vasen ’ ka , per il cavallo , non ci si mise a camminare .\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:It is so long...'\n",
      "TARGET:Come da tempo....\n",
      "PREDICTED:È così poco ...\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:Then Harris and I, having finished up the few things left on the table, carted out our luggage on to the doorstep, and waited for a cab.\n",
      "TARGET:Poi Harris e io, preparate le poche carabattole rimaste sul tavolino, trasportammo tutto il bagaglio sulla soglia di casa, e aspettammo una carrozza.\n",
      "PREDICTED:Allora Harris e io , dopo aver finito di andare nella tavola , la cena sulla riva , la carrozza e aspettava un biglietto .\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:'Is that true?' she said, looking into his eyes.\n",
      "TARGET:— Davvero? — disse lei, guardandolo negli occhi.\n",
      "PREDICTED:— È vero che è vero ? — ella disse , guardando negli occhi .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs = 10,\n",
    "    #callbacks = RichProgressBar(leave=True),\n",
    ")\n",
    "model = lit_module()\n",
    "# Train the PyTorch Lightning model\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
